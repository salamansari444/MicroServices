<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Build lean Node.js container images with UBI and Podman</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/05/17/build-lean-nodejs-container-images-ubi-and-podman" /><author><name>Evan Shortiss</name></author><id>e02331c3-e1ff-4cd5-b43f-8ebc71e5f23f</id><updated>2023-05-17T07:00:00Z</updated><published>2023-05-17T07:00:00Z</published><summary type="html">&lt;p&gt;Building a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; image for your &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; application might sound like a trivial task, but there are some pitfalls you’ll want to avoid along the path to containerizing your application. It is all too easy to accidentally include sensitive files, run more than one process in the container, run as root, or ship bloated container images. Because all of these mistakes reflect an image constructed without due care, reducing bloat reduces them all.&lt;/p&gt; &lt;p&gt;This post focuses on the “bloated container images” mistake that’s pretty easy to make when building Node.js application container images. Keep reading to learn about container image layers, how you can slim down a Node.js container image based on &lt;a href="https://developers.redhat.com/products/rhel/ubi"&gt;Red Hat’s Universal Base Images&lt;/a&gt; by over 70% (see Figure 1), and even more &lt;a href="https://developers.redhat.com/articles/2021/08/26/introduction-nodejs-reference-architecture-part-5-building-good-containers"&gt;best practices for building containers&lt;/a&gt;.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/image1_16.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/image1_16.png?itok=E9w80EPK" width="600" height="414" alt="A graph comparing the size of container images for a Node.js application depending on the build-strategy and base image used." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Image sizes resulting from a various build approaches using Red Hat's Universal Base Images for Node.js.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;Note:&lt;/strong&gt; All of the examples and code used in this post can be found in &lt;a href="https://github.com/evanshortiss/nodejs-container-builds-example"&gt;this repository on GitHub&lt;/a&gt;. You’ll need Node.js 18 and either Docker or Podman installed to follow along. &lt;a href="https://podman-desktop.io/"&gt;Podman&lt;/a&gt; is the container engine used for the examples in this post. Substitute &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;docker&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; in place of &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;podman&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; in commands if you’re using Docker instead of Podman. &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Building a Node.js application container image&lt;/h2&gt; &lt;p&gt;The Node.js documentation provides a great overview of how to &lt;a href="https://nodejs.org/en/docs/guides/nodejs-docker-webapp/"&gt;configure a Containerfile (also known as a Dockerfile)&lt;/a&gt; for a basic Node.js application. Let’s use that as a template to create a container image for a Node.js application. This application will use the &lt;a href="https://fastify.io"&gt;Fastify framework&lt;/a&gt; and TypeScript, but it’s worth noting that this guide is applicable to any Node.js web framework.&lt;/p&gt; &lt;p&gt;To get started, generate a new Fastify project that uses TypeScript using the Fastify CLI:&lt;/p&gt; &lt;pre&gt; npx fastify-cli@5 generate --lang=ts nodejs-ts-basic # Change into the project directory and generate a package-lock.json cd nodejs-ts-basic npm i --package-lock-only&lt;/pre&gt; &lt;p&gt;&lt;br /&gt; Create a &lt;strong&gt;Containerfile&lt;/strong&gt; in the new &lt;code&gt;nodejs-ts-basic&lt;/code&gt; project directory with the following contents:&lt;/p&gt; &lt;pre&gt; FROM registry.access.redhat.com/ubi8/nodejs-18 WORKDIR /usr/src/app # Copy in package.json and package-lock.json COPY --chown=1001:1001 package*.json ./ # Install dependencies and devDependencies RUN npm ci # Copy in source code and other assets COPY --chown=1001:1001 . . # Compile the source TS into JS files RUN npm run build:ts # Configure fastify behaviour, and NODE_ENV ENV NODE_ENV=production ENV FASTIFY_PORT 8080 ENV FASTIFY_ADDRESS 0.0.0.0 EXPOSE 8080 # Set the fastify-cli binary as the entrypoint ENTRYPOINT [ "./node_modules/.bin/fastify" ] # Launch the container by passing these parameters to the entrypoint # These parameters can be overridden if you’d like CMD [ "start", "-l", "info", "dist/app.js" ]&lt;/pre&gt; &lt;p&gt;&lt;br /&gt; Next, create a &lt;code&gt;.dockerignore&lt;/code&gt; file in the root of the repository. This works similar to a &lt;code&gt;.gitignore&lt;/code&gt;, but is respected by tools like Podman and Docker. It’s used to avoid copying the specified files into a container image:&lt;/p&gt; &lt;pre&gt; # Change this as necessary for your own project(s) Containerfile* README.md dist node_modules test *.log .dockerignore .taprc .npmrc .env* &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; With these files in place, build a container image using the Podman (or Docker) CLI:&lt;/p&gt; &lt;pre&gt; podman build . -f Containerfile -t nodejs-ts-basic &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; The resulting container image is approximately 831 MB in size. That's 188 MB larger than the &lt;a href="https://catalog.redhat.com/software/containers/ubi8/nodejs-18/6278e5c078709f5277f26998?container-tabs=gti"&gt;UBI Node.js v18 base image&lt;/a&gt;! Investigate the size of files and folders by running the &lt;code&gt;du&lt;/code&gt; command inside the container:&lt;/p&gt; &lt;pre&gt; podman run --rm nodejs-ts-basic /bin/du -h -d 1 60K ./dist 28K ./src 190M ./node_modules 190M . &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; Clearly the &lt;code&gt;node_modules&lt;/code&gt; folder is causing bloat in the image, because both the &lt;code&gt;dependencies&lt;/code&gt; and the &lt;code&gt;devDependencies&lt;/code&gt; specified in the package.json were installed. &lt;/p&gt; &lt;h2&gt;Attempting to slim down the Node.js container image&lt;/h2&gt; &lt;p&gt;A seemingly obvious solution to this problem is to remove those &lt;code&gt;devDependencies&lt;/code&gt; from the image. Try that by adding &lt;code&gt;npm prune --omit=dev&lt;/code&gt; after the &lt;code&gt;npm run build:ts&lt;/code&gt; command in the &lt;strong&gt;Containerfile&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt; RUN npm run build:ts RUN npm prune --omit=dev &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; And building it:&lt;/p&gt; &lt;pre&gt; podman build . -f Containerfile -t nodejs-ts-basic-prune &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; The container image will be more lightweight, right? Let's check:&lt;/p&gt; &lt;pre&gt; podman images --format '{{.Size}} {{.Repository}}' | grep nodejs 831 MB localhost/nodejs-ts-basic 832 MB localhost/nodejs-ts-basic-prune &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; This new image is larger than the last one! This is because container images are composed of layers. Each layer stores changes compared to the prior layer it's based on. The &lt;code&gt;npm prune&lt;/code&gt; command removed the &lt;code&gt;devDependencies&lt;/code&gt; from the final container image layer (you can confirm using the &lt;code&gt;du&lt;/code&gt; command shown previously), but the layer containing them is still there. Confirm this using the &lt;code&gt;podman history localhost/nodejs-ts-basic-prune&lt;/code&gt; command, noting that the &lt;strong&gt;npm ci&lt;/strong&gt; layer is there, and is over 187 MB in size.&lt;/p&gt; &lt;h2&gt;Multi-stage builds to the rescue&lt;/h2&gt; &lt;p&gt;A great solution to this problem is to use a &lt;a href="https://docs.docker.com/build/building/multi-stage/"&gt;multi-stage build&lt;/a&gt;. Multi-stage builds perform some of the build steps in separate containers, and copy only what‘s needed into the final container image. This reduces the number of layers and overall size of the final container image.&lt;/p&gt; &lt;p&gt;This is an example of a multi-stage &lt;strong&gt;Containerfile&lt;/strong&gt; that can be used to slim down the Node.js container image:&lt;/p&gt; &lt;pre&gt; # First stage of the build is to install dependencies, and build from source FROM registry.access.redhat.com/ubi8/nodejs-18 as build WORKDIR /usr/src/app COPY --chown=1001:1001 package*.json ./ RUN npm ci COPY --chown=1001:1001 tsconfig*.json ./ COPY --chown=1001:1001 src src RUN npm run build:ts # Second stage of the build is to create a lighter container with just enough # required to run the application, i.e production deps and compiled js files FROM registry.access.redhat.com/ubi8/nodejs-18 WORKDIR /usr/src/app COPY --chown=1001:1001 --from=build /usr/src/app/package*.json/ . RUN npm ci --omit=dev COPY --chown=1001:1001 --from=build /usr/src/app/dist/ dist/ ENV NODE_ENV=production ENV FASTIFY_PORT 8080 ENV FASTIFY_ADDRESS 0.0.0.0 EXPOSE 8080 ENTRYPOINT [ "./node_modules/.bin/fastify" ] CMD [ "start", "-l", "info", "dist/app.js" ] &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; A summary of the two stages:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The first stage (&lt;strong&gt;build&lt;/strong&gt;) installs all dependencies, and compiles the TypeScript code.&lt;/li&gt; &lt;li&gt;The second stage copies the compiled code from the &lt;em&gt;build&lt;/em&gt; image and installs only the production dependencies to produce a deployable container image.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The initial build using this multi-stage &lt;strong&gt;Containerfile&lt;/strong&gt; will be slower, but subsequent builds benefit from cached layers and are only a second or two slower than the single stage build. &lt;/p&gt; &lt;p&gt;The multi-stage build results in a container image that's just 661 MB. That’s 20% smaller than the single stage image’s 831 MB. This isn’t bad—but you can do better.&lt;/p&gt; &lt;h2&gt;Going minimal&lt;/h2&gt; &lt;p&gt;There’s one last step you can take to really slim this Node.js container image down; and that’s using a minimal base image. A minimal base image contains as few tools and libraries as possible, which means they have a significantly smaller footprint. &lt;/p&gt; &lt;p&gt;Modifying the second stage of the multi-stage build to use &lt;a href="https://catalog.redhat.com/software/containers/rhel8/nodejs-18-minimal/627d1b055365187064a0c9db?container-tabs=gti"&gt;Red Hat's minimal Node.js v18 Universal Base Image&lt;/a&gt; reduces the final container image size to just 211 MB. All you need to do is change the &lt;code&gt;FROM&lt;/code&gt; statement to use the minimal image:&lt;/p&gt; &lt;pre&gt; FROM registry.access.redhat.com/ubi8/nodejs-18-minimal &lt;/pre&gt; &lt;p&gt;&lt;br /&gt; That 211 MB container image is 75% smaller than the first 831 MB container image you built! Not only is the image smaller, but it also has a lower risk profile since it doesn’t contain tools that could be used for malicious purposes in the event of a security breach.&lt;/p&gt; &lt;h2&gt;Summary and next steps&lt;/h2&gt; &lt;p&gt;Use the following tips to improve your container images for any application runtime:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Use a trusted base image, such as &lt;a href="https://catalog.redhat.com/software/containers/search?q=ubi%20nodejs&amp;p=1"&gt;Red Hat’s Universal Base Image&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Don’t run as root. Using a Red Hat Universal Base Image takes care of this by default.&lt;/li&gt; &lt;li&gt;Use multi-stage builds to minimize container image layers.&lt;/li&gt; &lt;li&gt;Choose a minimal base image for the final stage in a multi-stage build.&lt;/li&gt; &lt;li&gt;Use a &lt;code&gt;.dockerignore&lt;/code&gt; file to keep unwanted files being copied into your container images.&lt;/li&gt; &lt;li&gt;Handle signals such as SIGINT and SIGTERM, or use &lt;a href="https://github.com/krallin/tini"&gt;tini&lt;/a&gt; or &lt;a href="https://github.com/Yelp/dumb-init"&gt;dumb-init&lt;/a&gt; to manage your process(es).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Take a look at &lt;a href="https://developers.redhat.com/articles/2021/11/08/optimize-nodejs-images-ubi-8-nodejs-minimal-image"&gt;this post by Bethany Griggs&lt;/a&gt; when you’re ready to deploy your lean Node.js container images on the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/05/17/build-lean-nodejs-container-images-ubi-and-podman" title="Build lean Node.js container images with UBI and Podman"&gt;Build lean Node.js container images with UBI and Podman&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Evan Shortiss</dc:creator><dc:date>2023-05-17T07:00:00Z</dc:date></entry><entry><title type="html">Kogito 1.37.0 released!</title><link rel="alternate" href="https://blog.kie.org/2023/05/kogito-1-37-0-released.html" /><author><name>Cristiano Nicolai</name></author><id>https://blog.kie.org/2023/05/kogito-1-37-0-released.html</id><updated>2023-05-16T10:42:39Z</updated><content type="html">We are glad to announce that the Kogito 1.37.0 release is now available! This goes hand in hand with , release. From a feature point of view, we have included a series of new features and bug fixes, including: * ForEach state actions now can access the result of the previous action within the same iteration by using $WORKFLOW.prevActionResult. This allows action chaining in SWF loops. * When a task is not found, the GET rest API method now returns 404.  * New APIs to read and write a workflow definition from a yaml/json file * Sysout custom action now uses S4LJ rather than System.out. It optionally allows setting up the log level by adding it to the operation string.  * Service Discovery property expansion now supports the simplified format knative:&lt;namespace&gt;/&lt;serviceName&gt; For more details head to the complete . All artifacts are available now: * Kogito runtime artifacts are available on Maven Central. * Kogito examples can be found . * Kogito images are available on . * Kogito operator is available in the in OpenShift and Kubernetes. * Kogito tooling 0.28.0 artifacts are available at the . A detailed changelog for 1.37.0 can be found in . New to Kogito? Check out our website . Click the "Get Started" button. The post appeared first on .</content><dc:creator>Cristiano Nicolai</dc:creator></entry><entry><title>The benefits of Fedora 38 long double transition in ppc64le</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/05/16/benefits-fedora-38-long-double-transition-ppc64le" /><author><name>Tulio Magno Quites Machado Filho</name></author><id>d06118ad-f5ac-4f38-b98b-6c5dbb3514a6</id><updated>2023-05-16T07:00:00Z</updated><published>2023-05-16T07:00:00Z</published><summary type="html">&lt;p&gt;Fedora 38 will have a new feature for ppc64le. Clang has begun using the IEEE 128-bit long double by default instead of the IBM 128-bit long double format. This allows Clang to behave the same way as GCC, which switched to IEEE 128-bit long double on ppc64le on &lt;a href="https://fedoraproject.org/wiki/Releases/36/ChangeSet#New_128-bit_IEEE_long_double_ABI_for_IBM_64-bit_POWER_LE"&gt;Fedora 36&lt;/a&gt;. This floating point format benefits from the hardware implementation available on IBM® Power9® processor-based servers and IBM® Power10™ processor-based servers.&lt;/p&gt; &lt;h2 id="background"&gt;Background of the floating point format&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://en.wikipedia.org/wiki/IBM_System/360_Model_85"&gt;IBM System/360 Model 85&lt;/a&gt; was released in 1968 and supported a 128-bit extended precision floating point format. A few decades later this format became known in the open source communities as IBM 128-bit long double or IBM double-double.&lt;/p&gt; &lt;p&gt;This floating point format provides a mantissa of 106 bits, 11 bits for the exponent and a signal bit. Meanwhile, its 64-bit floating point format provides a matissa of 53 bits, 11 bits as the exponent and a signal bit. According to the &lt;a href="https://www.ibm.com/docs/en/aix/7.1?topic=sepl-128-bit-long-double-floating-point-data-type"&gt;IBM® AIX® documentation&lt;/a&gt;, this data type can store numbers with more precision than the 64-bit data type, it does not store numbers of greater magnitude.&lt;/p&gt; &lt;p&gt;In 1985, the IEEE 754 Working Group for binary floating-point arithmetic established the &lt;a href="https://en.wikipedia.org/wiki/IEEE_754"&gt;IEEE Standard 754-1985&lt;/a&gt;, defining two binary floating point formats: a 32-bit (&lt;code&gt;binary32&lt;/code&gt;) and a 64-bit (&lt;code&gt;binary64&lt;/code&gt;). The C language was also in the process of standardization, requiring compilers to support at least three different binary floating point types called &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;double&lt;/code&gt;, and &lt;code&gt;long double&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The ppc64le architecture on Linux adopted the &lt;code&gt;binary32&lt;/code&gt; format as &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;binary64&lt;/code&gt; as &lt;code&gt;double&lt;/code&gt; and &lt;code&gt;ibm128&lt;/code&gt; as &lt;code&gt;long double&lt;/code&gt;, inheriting the same formats for the newer little endian architecture used on the older big endian ppc64.&lt;/p&gt; &lt;p&gt;In 2008, the IEEE Computer Society published the IEEE Std 754-2008, introducing an 128-bit binary floating point format (&lt;code&gt;binary128&lt;/code&gt;).&lt;/p&gt; &lt;table&gt;&lt;thead&gt;&lt;tr class="header"&gt;&lt;th&gt;Format&lt;/th&gt; &lt;th&gt;Signal bits&lt;/th&gt; &lt;th&gt;Exponent bits&lt;/th&gt; &lt;th&gt;Mantissa bits&lt;/th&gt; &lt;th&gt;Size (Bytes)&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr class="odd"&gt;&lt;td&gt;&lt;code&gt;binary32&lt;/code&gt;&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;8&lt;/td&gt; &lt;td&gt;24&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt;&lt;tr class="even"&gt;&lt;td&gt;&lt;code&gt;binary64&lt;/code&gt;&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;53&lt;/td&gt; &lt;td&gt;8&lt;/td&gt; &lt;/tr&gt;&lt;tr class="odd"&gt;&lt;td&gt;&lt;code&gt;binary128&lt;/code&gt;&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;15&lt;/td&gt; &lt;td&gt;113&lt;/td&gt; &lt;td&gt;16&lt;/td&gt; &lt;/tr&gt;&lt;tr class="even"&gt;&lt;td&gt;&lt;code&gt;ibm128&lt;/code&gt;&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;106&lt;/td&gt; &lt;td&gt;16&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;In 2017, IBM introduced the Power9 processor with native hardware support for the &lt;code&gt;binary128&lt;/code&gt; format, leading the way to changing the default &lt;code&gt;long double&lt;/code&gt; type used in C and C++. However, this transition occurred only on ppc64le because it requires an IBM® Power8® processor or newer. The same transition on ppc64 is more complex because it may run on processors that do not support 128-bit registers from VSX or Altivec, requiring an emulation to happen on 64-bit general purpose registers as well as different rules for argument passing.&lt;/p&gt; &lt;h2&gt;How to transition to IEEE 128-bit long double&lt;/h2&gt; &lt;p&gt;In most cases, programs and libraries will not require any modifications. They must be rebuilt with the Clang provided with Fedora 38 to start using the IEEE 128-bit long double. While &lt;a href="https://www.nextplatform.com/2016/08/24/big-blue-aims-sky-power9/"&gt;IBM Power9&lt;/a&gt; introduced native hardware support for &lt;code&gt;binary128&lt;/code&gt;, a &lt;code&gt;long double&lt;/code&gt; based on this format also works on IBM Power8. The only difference is the performance improvement that newer processors provide.&lt;/p&gt; &lt;p&gt;Note that programs built with a previous version of Clang will continue to work using the IBM 128-bit long double.&lt;/p&gt; &lt;h3&gt;Adapting code to IEEE 128-bit long double&lt;/h3&gt; &lt;p&gt;There is a small group of programs that make assumptions about which &lt;code&gt;long double&lt;/code&gt; format ppc64le uses. In those cases, these programs have to be modified.&lt;/p&gt; &lt;p&gt;When rewriting this code, I suggest taking advantage of the features provided by the ISO C standard to write code that will be executed correctly on different processors and operating systems, regardless of the &lt;code&gt;long double&lt;/code&gt; format used by the C Library (e.g., using the &lt;a href="https://www.gnu.org/software/libc/manual/html_node/Floating-Point-Parameters.html#index-LDBL_005fMANT_005fDIG"&gt;macro LDBL_MANT_DIG&lt;/a&gt;) as follows:&lt;/p&gt; &lt;div class="sourceCode" id="cb1"&gt; &lt;pre class="c sourceCode"&gt; &lt;code class="sourceCode c"&gt;&lt;span class="pp"&gt;#include &lt;span class="im"&gt;&lt;float.h&gt; &lt;span class="pp"&gt;#if LDBL_MANT_DIG == 113 &lt;span class="co"&gt;/* Insert code for IEEE binary128 long double. */ &lt;span class="pp"&gt;#elif LDBL_MANT_DIG == 106 &lt;span class="co"&gt;/* Insert code for IBM 128-bit long double. */ &lt;span class="pp"&gt;#elif LDBL_MANT_DIG == 64 &lt;span class="co"&gt;/* Insert code for Intel 80-bit long double. */ &lt;span class="pp"&gt;#elif LDBL_MANT_DIG == 53 &lt;span class="co"&gt;/* Insert code for IEEE binary64 long double. */ &lt;span class="pp"&gt;#endif&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h2&gt;You can still use IBM 128-bit long double&lt;/h2&gt; &lt;p&gt;It is also possible to continue using the IBM 128-bit long double with Clang on Fedora 38. When building the source code, ensure the parameters &lt;code&gt;-mabi=ibmlongdouble -mlong-double-128&lt;/code&gt; are passed to Clang as follows:&lt;/p&gt; &lt;div class="sourceCode" id="cb2"&gt; &lt;pre class="sh sourceCode"&gt; &lt;code class="sourceCode bash"&gt;$ clang -c -mabi=ibmlongdouble &lt;span class="at"&gt;-mlong-double-128 test.c -o test.o&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;p&gt;The same parameters also work on GCC.&lt;/p&gt; &lt;p&gt;C++ programs built with Clang must also get linked to libstdc++ because other libraries, such as libc++, do not support both &lt;code&gt;long double&lt;/code&gt; formats. The Fedora builds of Clang use libstdc++ by default, but if you would like to enforce the usage of libstdc++, use &lt;code&gt;-stdlib=libstdc++&lt;/code&gt; when calling &lt;code&gt;clang++&lt;/code&gt;, as follows:&lt;/p&gt; &lt;div class="sourceCode" id="cb3"&gt; &lt;pre class="sh sourceCode"&gt; &lt;code class="sourceCode bash"&gt;$ clang++ &lt;span class="at"&gt;-c -mabi=ibmlongdouble &lt;span class="at"&gt;-mlong-double-128 &lt;span class="at"&gt;-stdlib&lt;span class="op"&gt;=libstdc++ test.cc &lt;span class="at"&gt;-o test.o&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h2&gt;Benefits of transitioning to IEEE 128-bit long double&lt;/h2&gt; &lt;p&gt;The transition to IEEE 128-bit long double on ppc64le will allow programs to compute numbers with greater magnitude and more precision without causing any performance regressions on IBM Power9 and newer processors. This transition is expected to help scientific and engineering programs as well as improve platform compatibility with well-established standards.&lt;/p&gt; &lt;p&gt;Feel free to comment below if you have questions or comments. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/05/16/benefits-fedora-38-long-double-transition-ppc64le" title="The benefits of Fedora 38 long double transition in ppc64le"&gt;The benefits of Fedora 38 long double transition in ppc64le&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Tulio Magno Quites Machado Filho</dc:creator><dc:date>2023-05-16T07:00:00Z</dc:date></entry><entry><title type="html">Q2 2023 RESTEasy Quarterly Releases</title><link rel="alternate" href="https://resteasy.dev/2023/05/16/resteasy-releases/" /><author><name /></author><id>https://resteasy.dev/2023/05/16/resteasy-releases/</id><updated>2023-05-16T04:11:11Z</updated><dc:creator /></entry><entry><title type="html">SERVERLESS WORKFLOW EDITOR NEW FEATURE: JQ EXPRESSION AUTO COMPLETIONS</title><link rel="alternate" href="https://blog.kie.org/2023/05/serverless-workflow-editor-new-feature-jq-expression-auto-completions.html" /><author><name>Ajay Jaganathan</name></author><id>https://blog.kie.org/2023/05/serverless-workflow-editor-new-feature-jq-expression-auto-completions.html</id><updated>2023-05-15T16:23:06Z</updated><content type="html">In Serverless Workflow each instance is associated with a data model. These models consist of JSON objects. The data inside these models needs to be accessed and updated throughout the flow execution. jq is a powerful filtering tool that makes working with JSON data seamless. The Serverless Workflow specification supports the use of in multiple places. WHAT’S NEW? In order to improve the authoring experience for the user while working with these expressions, a new auto-completion capability is added to the editor. These features are available in the VS Code extension as well as the Serverless Logic Web Tools and work with both JSON and YAML files. REQUIREMENTS: * (0.28.0) * (0.28.0) * (1.66.0+) The jq auto-completion feature can be categorized into three: * The built-in functions * The workflow variables * The reusable function expressions THE BUILT-IN FUNCTIONS: These are functions provided by jq out of the box. These functions come in handy to do a lot of operations like max, min, length, etc. The completion provides a list of these functions along with a description of what it does so that the user does not have to read the docs every time. More information on the built-in functions can be found . Built-in function completions THE WORKFLOW VARIABLES: Workflow variable completions The serverless workflow works with a lot of variables, which are provided to the project in the form of a JSON schema, an open API file, or an async API file. A Variable in Serverless Workflow always starts with a .(DOT). The auto-completion feature parses these files (if present), extracts the variables, and provides the completion result to the user. Please note that the auto-completion feature is able to parse files in a remote URL as well as a local file system. In the first part of the video above, there is a JSON schema file present in the path: resources/schema/expression.json. The jq expressions can work in certain places and one of them is in the operation of functions which is of type expression. As you can see, the JSON schema has numbers, x, and y in its properties which are listed in the completion items. Please note that remote URLs are also supported for JSON schema. In the second part of the video, we have a function (Check action on RHODS) and this is an OpenAPI specification. We use a remote URL here and we see in the OpenAPI file some parameters available like noOfRunningPods, avgLoad, etc while trying to use the auto-complete we can see these values appearing in the completion item list. Please note that local files (eg: resources/spec/multiplication.yaml) also works. In the third part of the video we have a function which is of type async API and the corresponding file is present in the resources/spec/resume-event.yaml. When trying to auto-complete, we parse the async api file and extract the parameters out of it and show the completion items. Please note that this also works with remote URLs. THE REUSABLE FUNCTION EXPRESSIONS: A reusable is a function definition inside the functions array, which has a type (field) expression and a jq expression as the value for the operation field. These functions can be reused in the specification using the fn: followed by name of the function. The auto-completion feature also provides a list of these functions present in the functions array. Reusable function expression completion Note: The expressions can be used in various places. To know more about the usage please visit . CONCLUSION: The auto-completion feature assists the user in writing the jq expressions and thus improves the authoring experience. In order to learn more about the jq expression in Serverless Workflow, please visit our blog post on  . Stay tuned to get more updates on the upcoming features for the Serverless Workflow. The post appeared first on .</content><dc:creator>Ajay Jaganathan</dc:creator></entry><entry><title>How to use the new OpenShift quick starts to deploy JBoss EAP</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/05/15/how-use-new-openshift-quick-starts-deploy-jboss-eap" /><author><name>Philip Hayes</name></author><id>b003b810-2061-4968-b29f-1864808c85b3</id><updated>2023-05-15T07:00:00Z</updated><published>2023-05-15T07:00:00Z</published><summary type="html">&lt;p&gt;In the articles, &lt;a href="https://developers.redhat.com/articles/2022/01/12/how-migrate-your-java-applications-red-hat-openshift"&gt;How to migrate your Java applications to Red Hat OpenShift&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2022/10/13/how-deploy-jboss-eap-applications-openshift-pipelines"&gt;How to deploy JBoss EAP applications with OpenShift Pipelines&lt;/a&gt;, we covered the technologies utilized to build and deploy &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/application-platform"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; images on OpenShift. These technologies include Source to Image (S2I), Helm charts, build configs, deployment configs, tekton pipelines, and ingress routes. While these technologies will be familiar to developers experienced with Kubernetes and containerization, a Jakarta EE developer coming from a traditional JBoss EAP background may be new to these tools.&lt;/p&gt; &lt;p&gt;To help bridge the gap between traditional EAP deployments and OpenShift deployments, Red Hat has created a series of OpenShift quick starts focused on the tools and techniques involved with building and deploying JBoss EAP images on OpenShift. These quick starts provide step-by-step instructions for deploying a JBoss EAP application on OpenShift. They will also explain what is happening at each stage and how to validate each stage you complete.&lt;/p&gt; &lt;p&gt;The first quick start released is a simple JBoss EAP "Hello World" application deployment using Helm charts. This quick start includes the following tasks:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Creating a JBoss EAP 7 application with Helm.&lt;/li&gt; &lt;li aria-level="1"&gt;Viewing the Helm release.&lt;/li&gt; &lt;li aria-level="1"&gt;Viewing the associated code.&lt;/li&gt; &lt;li aria-level="1"&gt;Viewing the build status.&lt;/li&gt; &lt;li aria-level="1"&gt;Viewing the pod status.&lt;/li&gt; &lt;li aria-level="1"&gt;Running the JBoss EAP 7 application.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;We will demonstrate quick start in this article.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;OpenShift CLI tool (optional)&lt;/li&gt; &lt;li aria-level="1"&gt;Openshift 4.x cluster with cluster admin permissions&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The quick start will be available with OpenShift 4.14.  In the mean time, you can add it by following the instructions below.&lt;/p&gt; &lt;h2&gt;Install the quick start using OpenShift CLI&lt;/h2&gt; &lt;p&gt;To download the OpenShift CLI, follow these steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Click on the &lt;strong&gt;?&lt;/strong&gt; in the top right hand corner of the OpenShift UI.&lt;/li&gt; &lt;li&gt;Select &lt;strong&gt;Command line tools&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Download and install the command line client for your OS.&lt;/li&gt; &lt;li&gt;Log in as cluster admin.&lt;/li&gt; &lt;li&gt;Run the following command:&lt;/li&gt; &lt;/ol&gt;&lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/jboss-eap-up-and-running/openshift-console-quickstarts/main/jboss-eap7-with-helm.yaml&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Install the quick start using the OpenShift UI&lt;/h2&gt; &lt;p&gt;After logging in to OpenShift as cluster administrator, follow these steps:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;To create the quick start via the OpenShift UI, click on the &lt;strong&gt;+&lt;/strong&gt; icon in the top right hand corner of the UI.&lt;/li&gt; &lt;li&gt;Paste the contents of this link: https://raw.githubusercontent.com/jboss-eap-up-and-running/openshift-console-quickstarts/main/jboss-eap7-with-helm.yaml&lt;/li&gt; &lt;li&gt;Click on &lt;strong&gt;Create&lt;/strong&gt; to create the quick start.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Deploy JBoss EAP 7 using quick start&lt;/h2&gt; &lt;p&gt;In the OpenShift developer UI, click &lt;strong&gt;+Add&lt;/strong&gt; and select &lt;strong&gt;View all quick starts&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;In the search field, enter &lt;strong&gt;eap&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;When you see the &lt;strong&gt;Get started with JBoss EAP 7 using a Helm Chart&lt;/strong&gt; quick start listed (Figure 1), select this quick start to begin.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/start_0.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/start_0.jpg?itok=xkUK-gmG" width="600" height="350" alt="The get started with JBoss EAP 7 using a Helm Chart option is shown in Red Hat OpenShift UI." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The JBoss EAP quick start page.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;When a panel opens with instructions, click &lt;strong&gt;Start&lt;/strong&gt; to begin (Figure 2).&lt;/p&gt; &lt;p&gt;In this initial panel, you will follow the steps required to locate and install the JBoss EAP 7.4 Helm chart. You don't need to change any default settings presented by the Helm configuration.&lt;/p&gt; &lt;p&gt;Once you click &lt;strong&gt;Install&lt;/strong&gt;, the user interface will switch to the Topology view and show the &lt;strong&gt;Release notes&lt;/strong&gt; from the Helm chart, as shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/step2_0.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/step2_0.jpg?itok=hxw6ys2v" width="600" height="348" alt="A panel shows instructions to build and deploy a JBoss EAP application on OpenShift using Helm charts." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: The steps to build and deploy a JBoss EAP application on OpenShift using Helm charts.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Click &lt;strong&gt;Next&lt;/strong&gt; to open the &lt;strong&gt;Check your work&lt;/strong&gt; panel, as shown in Figure 3. This panel contains questions about the results. It gives you the opportunity to review your work and confirm that you successfully completed the task before advancing to the next task in the quick start.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/stage1-check.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/stage1-check.jpg?itok=YI5utL8U" width="384" height="319" alt="The quick start "Check your work" panel." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 3: The quick start "Check your work" panel, confirming Helm deployed.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This is where the quick start helps you understand what was created by the Helm chart. You will be able to identify the Helm release and the eap74 deployment. Click &lt;strong&gt;Yes&lt;/strong&gt; and then click &lt;strong&gt;Next&lt;/strong&gt; to move onto the next section.&lt;/p&gt; &lt;p&gt;This section will guide you through locating the Helm release we just installed. You will be able to view the list of resources (Figure 4).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/step3_0.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/step3_0.jpg?itok=1NUVTnI_" width="600" height="349" alt="A list of Helm chart resources." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: View a list of Helm chart resources.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;It will prompt you to verify the results again. Validate that you can see the deployed label next to the Helm release and click &lt;strong&gt;Next&lt;/strong&gt; to move to the next section.&lt;/p&gt; &lt;p&gt;You will now be guided through viewing the source code associated with the quick start. There is another verification to confirm that you have successfully completed this step.&lt;/p&gt; &lt;p&gt;Move on to the next section, which describes how the Helm release created two builds. The &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.4/html/getting_started_with_jboss_eap_for_openshift_container_platform/build_run_java_app_s2i#chained-build-support-eap_default"&gt;build process for JBoss EAP applications utilizes two builds&lt;/a&gt;, an artifact build and a runtime build. The artifact build performs a maven build to create the application artifact. The runtime build deploys the output of this build to an instance of EAP. This results in a much smaller footprint for the runtime image containing the minimum file necessary to run the application.&lt;/p&gt; &lt;p&gt;Once you have completed this check, click &lt;strong&gt;Yes&lt;/strong&gt; to move on to the next check where you will be directed back to view the topology and the running pod status. Follow the instructions to check the status of the pod and complete the check.&lt;/p&gt; &lt;p&gt;Finally, you will be shown how to open the application by clicking on the external URL. Once you have completed this stage, you can complete the final check.&lt;/p&gt; &lt;p&gt;Viewing the external URL will open up a new browser window shown in Figure 5:&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/final-page_0.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/final-page_0.jpg?itok=ltVqGRhZ" width="600" height="351" alt="The screen shows successful deployment of JBoss EAP application deployment on OpenShift." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 5: This page shows successful deployment of JBoss EAP application deployment on OpenShift.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You have now completed the quick start. You should see the completed stages of the quick start listed, as shown in Figure 6:&lt;/p&gt; &lt;figure class="align-center" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/final-ticks_0.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/final-ticks_0.jpg?itok=zyjkUmcC" width="419" height="466" alt="The completed stages of the quick start are listed." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 6: Quick start final checks listed.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;The new quick starts simplify JBoss EAP deployment&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated the new JBoss EAP quick start, designed to guide developers familiar with traditional &lt;a href="https://www.redhat.com/en/technologies/jboss-middleware/application-platform"&gt;JBoss EAP&lt;/a&gt; deployments through the steps to build and deploy application images on OpenShift. The quick start helps developers understand how to use Helm to create the build configs, deployment configs, and external routes required to build and deploy JBoss EAP applications on OpenShift. This quick start uses a sample Git repo with a sample EAP application. Developers will be able to use the same approach to use their own sample applications.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/05/15/how-use-new-openshift-quick-starts-deploy-jboss-eap" title="How to use the new OpenShift quick starts to deploy JBoss EAP"&gt;How to use the new OpenShift quick starts to deploy JBoss EAP&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Philip Hayes</dc:creator><dc:date>2023-05-15T07:00:00Z</dc:date></entry><entry><title type="html">Using Pact and Quarkus to Tame Microservices Testing</title><link rel="alternate" href="https://quarkus.io/blog/pact-and-quarkus-3/" /><author><name>Holly Cummins</name></author><id>https://quarkus.io/blog/pact-and-quarkus-3/</id><updated>2023-05-15T00:00:00Z</updated><content type="html">In a microservices architecture, making sure each microservices works is (relatively) easy. The microservices are usually small, and easy to test. But how do you make sure the microservices work together? How do you know if the system as a whole works? One answer is contract testing. Contract testing gives...</content><dc:creator>Holly Cummins</dc:creator></entry><entry><title type="html">New DMN boxed expression editor</title><link rel="alternate" href="https://blog.kie.org/2023/05/new-dmn-boxed-expression-editor.html" /><author><name>Jozef Marko</name></author><id>https://blog.kie.org/2023/05/new-dmn-boxed-expression-editor.html</id><updated>2023-05-12T16:45:40Z</updated><content type="html">We’re excited to announce the completion of the new generation of the Boxed Expression editor! We the beginning of this process some time ago, if you are a regular blog visitor you should remember that. During that time, we made the new component available on the Alpha version, giving the user the choice to use the stable version or experiment with the new one. During that phase, we received a lot of comments and suggestions to improve more the component, thanks to anyone involved! DMN MODERNIZATION The new version of the boxed expression editor represents the first step towards the ultimate goal of the DMN Editor modernization, which will include additional refactoring, technology updates, and general performance and usability improvements! With the , we are confident that the new boxed expression editor reached a good level of usability improvements. We tested the new component and summarized the unfinished tasks and the next features in . However, we are sure similar huge refactoring needs huge help from community members testing and giving feedback. So feel free to report a or contact us on chat. INLINE ADD ROWS/COLUMNS With this addition, users do not need to open the context menu and decide if they want to add rows or columns. Row leading cells or header menu cells display a small plus icon on hovering them. Once this plus icon is clicked, a row or column is added. Please notice the small plus icon in the bottom left corner of the picture below. COPY/CUT/PASTE ENTIRE EXPRESSIONS With this addition, users should be more productive in implementing similar expressions. Often it is a case users implement more expressions with just small differences. In the screenshot above, the user is copying the whole ‘Invocation’ expression. The same can be done for a whole root ‘Context’ expression from the screenshot. Once expression is copied or cut, user can invoke the same context menu over a target cell and click the ‘Paste’ option. THE NEW SELECTION MECHANISM With this addition, we bring user experience known from other grid/table editors, where users can select cells simply by dragging a rectangle over the desired area. In combination with copy and paste feature, it can be a very productive way to design a decision table. Imagine a scenario like below. Then simply press ‘Ctrl + S’, select the target top left cell, and press ‘Ctrl + V’ (shortcuts may differ across platforms) resulting in a decision table like below. RESIZING CELLS From now on, the user can resize cells using the new resizer bar. It is shown once a cell has hovered. Users can simply drag and drop it to resize a cell. Please notice the grey bar in the picture below next to the ‘Insufficient’ string. THE NEW INLINE DESCRIPTIONS With this addition, we are trying to make our tool more self documented. Especially for new users different hit policies and expression types may be confusing or not clear enough. We believe users will be more productive when they find some documentation for them directly in the tool. THE DMN RUNNER TABLE IMPROVED EXPERIENCE You will notice we are now reusing the box expression component for DMN Runner tabular view. That is a great step in unifying user experience during interacting with our tool in more places. We are going to bring the same component also for SceSim test scenarios, but it will be a topic for the next blog posts. In the meantime, feel free to try DMN Runner tabular view. The post appeared first on .</content><dc:creator>Jozef Marko</dc:creator></entry><entry><title type="html">Podman Desktop: A Beginner’s Guide to Containerization</title><link rel="alternate" href="https://www.mastertheboss.com/soa-cloud/docker/podman-desktop-a-beginners-guide-to-containerization/" /><author><name>F.Marchioni</name></author><id>https://www.mastertheboss.com/soa-cloud/docker/podman-desktop-a-beginners-guide-to-containerization/</id><updated>2023-05-12T08:47:50Z</updated><content type="html">Podman is a popular containerization tool that allows users to manage containers, images, and other related resources. The Podman Desktop Tool is an easy-to-use graphical interface for managing Podman containers on your desktop. In this tutorial, we’ll go over how to use the Podman Desktop Tool to manage WildFly container image, covering some of its ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Eclipse Vert.x 4.4.2 released!</title><link rel="alternate" href="https://vertx.io/blog/eclipse-vert-x-4-4-2" /><author><name>Julien Viet</name></author><id>https://vertx.io/blog/eclipse-vert-x-4-4-2</id><updated>2023-05-12T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.4.2 has just been released. It fixes CVE-2023-32081 and quite a few bugs that have been reported by the community</content><dc:creator>Julien Viet</dc:creator></entry></feed>
